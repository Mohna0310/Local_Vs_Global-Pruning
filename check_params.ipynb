{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, gen_emb, domain_emb, num_classes=3, dropout=0.5, crf=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.gen_embedding = torch.nn.Embedding(gen_emb.shape[0], gen_emb.shape[1])\n",
    "        self.gen_embedding.weight=torch.nn.Parameter(torch.from_numpy(gen_emb), requires_grad=False)\n",
    "        self.domain_embedding = torch.nn.Embedding(domain_emb.shape[0], domain_emb.shape[1])\n",
    "        self.domain_embedding.weight=torch.nn.Parameter(torch.from_numpy(domain_emb), requires_grad=False)\n",
    "    \n",
    "        self.conv1=torch.nn.Conv1d(gen_emb.shape[1]+domain_emb.shape[1], 128, 5, padding=2 )\n",
    "        self.conv2=torch.nn.Conv1d(gen_emb.shape[1]+domain_emb.shape[1], 128, 3, padding=1 )\n",
    "        self.dropout=torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.conv3=torch.nn.Conv1d(256, 256, 5, padding=2)\n",
    "        self.conv4=torch.nn.Conv1d(256, 256, 5, padding=2)\n",
    "        self.conv5=torch.nn.Conv1d(256, 256, 5, padding=2)\n",
    "        self.linear_ae=torch.nn.Linear(256, num_classes)\n",
    "        self.crf_flag=crf\n",
    "        if self.crf_flag:\n",
    "            from allennlp.modules import ConditionalRandomField\n",
    "            self.crf=ConditionalRandomField(num_classes)            \n",
    "          \n",
    "    def forward(self, x, x_len, x_mask, x_tag=None, testing=False):\n",
    "        x_emb=torch.cat((self.gen_embedding(x), self.domain_embedding(x) ), dim=2)\n",
    "        x_emb=self.dropout(x_emb).transpose(1, 2)\n",
    "        x_conv=torch.nn.functional.relu(torch.cat((self.conv1(x_emb), self.conv2(x_emb)), dim=1) )\n",
    "        x_conv=self.dropout(x_conv)\n",
    "        x_conv=torch.nn.functional.relu(self.conv3(x_conv) )\n",
    "        x_conv=self.dropout(x_conv)\n",
    "        x_conv=torch.nn.functional.relu(self.conv4(x_conv) )\n",
    "        x_conv=self.dropout(x_conv)\n",
    "        x_conv=torch.nn.functional.relu(self.conv5(x_conv) )\n",
    "        x_conv=x_conv.transpose(1, 2)\n",
    "        x_logit=self.linear_ae(x_conv)\n",
    "        if testing:\n",
    "            if self.crf_flag:\n",
    "                score=self.crf.viterbi_tags(x_logit, x_mask)\n",
    "            else:\n",
    "                x_logit=x_logit.transpose(2, 0)\n",
    "                score=torch.nn.functional.log_softmax(x_logit).transpose(2, 0)\n",
    "        else:\n",
    "            if self.crf_flag:\n",
    "                score=-self.crf(x_logit, x_tag, x_mask)\n",
    "            else:\n",
    "                x_logit=torch.nn.utils.rnn.pack_padded_sequence(x_logit, x_len, batch_first=True)\n",
    "                score=torch.nn.functional.nll_loss(torch.nn.functional.log_softmax(x_logit.data), x_tag.data)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd global_laptop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd 95%/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('laptop0_global.pt') # laptop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_embedding.weight 154479\n",
      "domain_embedding.weight 37586\n",
      "conv1.bias 0\n",
      "conv1.weight 0\n",
      "conv2.bias 0\n",
      "conv2.weight 0\n",
      "conv3.bias 0\n",
      "conv3.weight 0\n",
      "conv4.bias 0\n",
      "conv4.weight 0\n",
      "conv5.bias 0\n",
      "conv5.weight 0\n",
      "linear_ae.bias 0\n",
      "linear_ae.weight 0\n",
      "\n",
      "Total parameters :  192065\n"
     ]
    }
   ],
   "source": [
    "# Full precision model's parameters after pruning\n",
    "params = 0\n",
    "p = []\n",
    "for i in model.state_dict().keys():\n",
    "  imd = (model.state_dict()[i] !=0.).sum().item()\n",
    "  print(i,imd)\n",
    "  p.append(imd)\n",
    "  params += imd\n",
    "\n",
    "print(\"\\nTotal parameters : \",params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573741603942444"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4505835 - params)/4505835 # Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4612835 - params)/4612835 # Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_embedding.weight  :   Pruned : 154479 FP :  2449800  >>>  0.9369421993632133\n",
      "domain_embedding.weight  :   Pruned : 37586 FP :  661600  >>>  0.943189238210399\n",
      "conv1.bias  :     Pruned : 0 FP :  128  >>>  1.0\n",
      "conv1.weight  :   Pruned : 0 FP :  256000  >>>  1.0\n",
      "conv2.bias  :     Pruned : 0 FP :  128  >>>  1.0\n",
      "conv2.weight  :   Pruned : 0 FP :  153600  >>>  1.0\n",
      "conv3.bias  :     Pruned : 0 FP :  256  >>>  1.0\n",
      "conv3.weight  :   Pruned : 0 FP :  327680  >>>  1.0\n",
      "conv4.bias  :     Pruned : 0 FP :  256  >>>  1.0\n",
      "conv4.weight  :   Pruned : 0 FP :  327680  >>>  1.0\n",
      "conv5.bias  :     Pruned : 0 FP :  256  >>>  1.0\n",
      "conv5.weight  :   Pruned : 0 FP :  327680  >>>  1.0\n",
      "linear_ae.bias  :     Pruned : 0 FP :  3  >>>  1.0\n",
      "linear_ae.weight  :   Pruned : 0 FP :  768  >>>  1.0\n",
      "\n",
      "Total parameters of FP:  4505835  Pruned : 192065  >>>  0.9573741603942444\n"
     ]
    }
   ],
   "source": [
    "#p1 = [2449800, 768600, 128, 256000, 128, 153600, 256,327680, 256, 327680, 256, 327680, 3, 768] # Restaurant\n",
    "p1 = [2449800, 661600, 128, 256000, 128, 153600, 256,327680, 256, 327680, 256, 327680, 3, 768]  # Laptop\n",
    "\n",
    "params = 0\n",
    "p2 = []\n",
    "for i,j,k in zip(model.state_dict().keys(), p, p1):\n",
    "    if 'bias' in i:\n",
    "        print(i,\" : \", \"   Pruned :\" ,j, \"FP : \", k, \" >>> \",(k-j)/k)\n",
    "    else:\n",
    "        print(i,\" : \", \" Pruned :\" ,j, \"FP : \", k, \" >>> \",(k-j)/k)\n",
    "    imd = (model.state_dict()[i] !=0.).sum().item()\n",
    "    p2.append(imd)\n",
    "    params += imd\n",
    "print()\n",
    "print(\"Total parameters of FP: \" , sum(p1), \" Pruned :\", params, \" >>> \",(sum(p1)-params)/sum(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
